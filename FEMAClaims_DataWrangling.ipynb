{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Two: Data Wrangling #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Collection\n",
    "\n",
    "- Import packages\n",
    "- Read in FEMA Redacted Claims dataset, dated 03-31-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset into dataframe called claims\n",
    "claims = pd.read_csv('data/openFEMA_claims20190331.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Organization\n",
    "\n",
    "- GitHub repository created\n",
    "- Folder structure created, dataset stored in data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Definition\n",
    "\n",
    "- Explore variables and entries of dataset\n",
    "- Identify issues that need to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2418007 entries, 0 to 2418006\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                      Non-Null Count    Dtype  \n",
      "---  ------                                      --------------    -----  \n",
      " 0   agriculturestructureindicator               153883 non-null   object \n",
      " 1   asofdate                                    2418007 non-null  object \n",
      " 2   basefloodelevation                          480501 non-null   float64\n",
      " 3   basementenclosurecrawlspacetype             2417962 non-null  float64\n",
      " 4   reportedcity                                2413501 non-null  object \n",
      " 5   condominiumindicator                        2359895 non-null  object \n",
      " 6   policycount                                 2417999 non-null  float64\n",
      " 7   countycode                                  2411261 non-null  float64\n",
      " 8   crsdiscount                                 2417999 non-null  float64\n",
      " 9   dateofloss                                  2418007 non-null  object \n",
      " 10  elevatedbuildingindicator                   2362655 non-null  object \n",
      " 11  elevationcertificateindicator               604633 non-null   object \n",
      " 12  elevationdifference                         2417999 non-null  float64\n",
      " 13  censustract                                 2359128 non-null  float64\n",
      " 14  floodzone                                   2255324 non-null  object \n",
      " 15  houseworship                                228993 non-null   object \n",
      " 16  latitude                                    2364893 non-null  float64\n",
      " 17  locationofcontents                          1523582 non-null  object \n",
      " 18  longitude                                   2364893 non-null  float64\n",
      " 19  lowestadjacentgrade                         347724 non-null   float64\n",
      " 20  lowestfloorelevation                        471935 non-null   float64\n",
      " 21  numberoffloorsintheinsuredbuilding          2401514 non-null  float64\n",
      " 22  nonprofitindicator                          232432 non-null   object \n",
      " 23  obstructiontype                             1530692 non-null  object \n",
      " 24  occupancytype                               2417287 non-null  float64\n",
      " 25  originalconstructiondate                    2051606 non-null  object \n",
      " 26  originalnbdate                              2417999 non-null  object \n",
      " 27  amountpaidonbuildingclaim                   2344874 non-null  float64\n",
      " 28  amountpaidoncontentsclaim                   1702351 non-null  float64\n",
      " 29  amountpaidonincreasedcostofcomplianceclaim  1148012 non-null  float64\n",
      " 30  postfirmconstructionindicator               2346037 non-null  object \n",
      " 31  ratemethod                                  2352804 non-null  object \n",
      " 32  smallbusinessindicatorbuilding              249630 non-null   object \n",
      " 33  state                                       2417995 non-null  object \n",
      " 34  totalbuildinginsurancecoverage              2417999 non-null  float64\n",
      " 35  totalcontentsinsurancecoverage              2417999 non-null  float64\n",
      " 36  yearofloss                                  2418007 non-null  int64  \n",
      " 37  reportedzip                                 2416876 non-null  object \n",
      " 38  primaryresidence                            1406474 non-null  object \n",
      "dtypes: float64(18), int64(1), object(20)\n",
      "memory usage: 719.5+ MB\n"
     ]
    }
   ],
   "source": [
    "claims.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Cleaning\n",
    "\n",
    "- Go through columns based on datatype (Y/N indicators, categorical, numerical, datetime)\n",
    "- Create NaN column for each variable to capture missing values\n",
    "- Fill NaNs in original columns with most appropriate value (e.g. create \"isnull\" category for categoricals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Y/N Indicator Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for handling missing values in Y/N indicator variables\n",
    "def YN_fill(df, col_list):\n",
    "    for col in col_list:\n",
    "        if set(df[col].unique()) == set(['N', 'Y', np.nan]):\n",
    "            df[col] = df[col].replace({'Y':0, 'N':1})\n",
    "            df[col] = df[col].fillna(2)\n",
    "            df[col] = df[col].astype(int)\n",
    "        else:\n",
    "            print('invalid column: ' + col)\n",
    "            \n",
    "# Create list of Y/N indicator variables\n",
    "YN_vars = ['agriculturestructureindicator', 'elevatedbuildingindicator', 'houseworship', 'nonprofitindicator', 'postfirmconstructionindicator', 'smallbusinessindicatorbuilding', 'primaryresidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid column: nonprofitindicator\n"
     ]
    }
   ],
   "source": [
    "# Call function\n",
    "YN_fill(claims, YN_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix invalid entries in nonprofitindicator\n",
    "claims['nonprofitindicator'] = claims['nonprofitindicator'].replace('0', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function again on nonprofitindicator\n",
    "YN_fill(claims, ['nonprofitindicator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Category Indicator Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to reclassify indicator categories by column, see datadictionary for definitions\n",
    "def reclass(df, col_list, r_dict_list):\n",
    "    for i in range(0,len(col_list)):\n",
    "        df[col_list[i]] = df[col_list[i]].replace(r_dict_list[i]) \n",
    "\n",
    "# Create reclassify dicts for each variable (num of floors and occtype ok as is)\n",
    "bdcst_d = {0.0:1, 1.0:2, 2.0:3, 3.0:4, 4.0:5}\n",
    "ci_d = {'N':1, 'U':2, 'A':3, 'H': 4, 'L':5, 'T': 6}\n",
    "crsd_d = {0.0: 10, 0.5: 9, 1.0:8, 1.5: 7, 2.0:6, 2.5:5, 3.0:4, 3.5:3, 4.0:2, 4.5:1}\n",
    "eci_d = {1.0:1, 2.0:2, 3.0:3, 4.0:4, 'A':5, 'B':6, 'C':7, 'D':8, 'E':9}\n",
    "loc_d = {'Lowest floor only above ground level (No basement/enclosure/crawlspace/subgrade crawlspace)':3, 'Lowest floor above ground level and higher floors (No basement/enclosure/crawlspace/subgrade crawlspace)':4, 'Basement/Enclosure/Crawlspace/Subgrade Crawlspace and above':2, 'Manufactured (mobile) home or travel trailer on foundation':6, 'Above ground level more than one full floor':5, 'Basement/Enclosure/Crawlspace/Subgrade Crawlspace only':1}\n",
    "ot_d = {'*':np.nan, 0:np.nan}\n",
    "rm_d = {'A': 10, 'B': 11, 'E':12, 'F':13, 'G':14, 'P':15, 'Q':16, 'S':17, 'T':18, 'W':19}\n",
    "\n",
    "# List of columns for reclassify\n",
    "reclass_col = ['basementenclosurecrawlspacetype','condominiumindicator', 'crsdiscount', 'elevationcertificateindicator', 'locationofcontents', 'obstructiontype', 'ratemethod']\n",
    "\n",
    "# List of dicts for reclassify\n",
    "reclass_dict = [bdcst_d, ci_d, crsd_d, eci_d, loc_d, ot_d, rm_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call reclassify function\n",
    "reclass(claims, reclass_col, reclass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn elevationcertificateindicator and ratemethod to numeric\n",
    "claims['elevationcertificateindicator'] = pd.to_numeric(claims['elevationcertificateindicator'])\n",
    "claims['ratemethod'] = pd.to_numeric(claims['ratemethod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for creating new column to track NaNs for indicator variables, fill NaNs with 0\n",
    "def create_nancol(df, col_list):\n",
    "    for col in col_list:\n",
    "        df[col+'_NaN'] = np.where(np.isnan(df[col].values), 1, 0)\n",
    "        df[col] = df[col].fillna(0)\n",
    "        df[col] = df[col].astype(int)\n",
    "        \n",
    "# Create list of indicator variables \n",
    "ind_vars = ['basementenclosurecrawlspacetype','condominiumindicator', 'crsdiscount', 'elevationcertificateindicator', 'locationofcontents', 'numberoffloorsintheinsuredbuilding', 'obstructiontype', 'occupancytype', 'ratemethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "create_nancol(claims, ind_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address floodzone, keep categories as strings, fill NaNs with 0\n",
    "claims['floodzone_NaN'] = claims['floodzone'].isnull().astype(int)\n",
    "claims['floodzone'] = claims['floodzone'].fillna('isnull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Numerical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NaN column function on numerical variables\n",
    "# Also fill with mode\n",
    "def create_nancol_num(df, col_list):\n",
    "    for col in col_list:\n",
    "        df[col+'_NaN'] = np.where(np.isnan(df[col].values), 1, 0)\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Create list of applicable columns\n",
    "num_vars = ['policycount', 'lowestadjacentgrade', 'lowestfloorelevation','amountpaidonbuildingclaim', 'amountpaidoncontentsclaim', 'amountpaidonincreasedcostofcomplianceclaim', 'totalbuildinginsurancecoverage', 'totalcontentsinsurancecoverage', 'elevationdifference', 'basefloodelevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "create_nancol_num(claims, num_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address invalid date entry in originalconstructiondate\n",
    "claims['originalconstructiondate'] = claims['originalconstructiondate'].replace('1111-11-11', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to create NaN column and turn date columns into datetime type\n",
    "def create_nancol_date(df, col_list):\n",
    "    for col in col_list:\n",
    "        df[col+'_NaN'] = df[col].apply(lambda x: 1 if x == np.nan else 0)\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "        \n",
    "# Create list of applicable columns\n",
    "date_vars = ['asofdate', 'dateofloss', 'originalconstructiondate', 'originalnbdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "create_nancol_date(claims, date_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other Cat Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create NaN column and fill NaNs with \"isnull\"\n",
    "def create_nancol_ocat(df, col_list):\n",
    "    for col in col_list:\n",
    "        df[col+'_NaN'] = df[col].isnull().astype(int)\n",
    "        df[col] = df[col].fillna('isnull')\n",
    "        \n",
    "# Create list of applicable columns\n",
    "ocat_vars = ['reportedcity', 'countycode', 'censustract', 'latitude', 'longitude', 'yearofloss', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "create_nancol_ocat(claims, ocat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address reportedzip\n",
    "# Replace invalid entries\n",
    "create_nancol_ocat(claims, ['reportedzip'])\n",
    "claims['reportedzip'] = claims['reportedzip'].replace(to_replace=r'^\\D\\d{5}\\D', value='invalid', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output cleaned dataset for next steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims.to_csv('data/claimsdata_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
