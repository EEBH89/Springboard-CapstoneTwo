{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEMA Flood Insurance Claim Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling, cleaning, and preprocessing for Springboard Capstone Project 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File openFEMA_claims20190331.csv does not exist: 'openFEMA_claims20190331.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f7b9149867ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in dataset into dataframe called claims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclaims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openFEMA_claims20190331.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File openFEMA_claims20190331.csv does not exist: 'openFEMA_claims20190331.csv'"
     ]
    }
   ],
   "source": [
    "# Read in dataset into dataframe called claims\n",
    "claims = pd.read_csv('openFEMA_claims20190331.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling and Cleaning <br>\n",
    "Explore variables, clean up invalid entries and fill missing values based on variable type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agriculturestructureindicator                 2264124\n",
       "asofdate                                            0\n",
       "basefloodelevation                            1937506\n",
       "basementenclosurecrawlspacetype                    45\n",
       "reportedcity                                     4506\n",
       "condominiumindicator                            58112\n",
       "policycount                                         8\n",
       "countycode                                       6746\n",
       "crsdiscount                                         8\n",
       "dateofloss                                          0\n",
       "elevatedbuildingindicator                       55352\n",
       "elevationcertificateindicator                 1813374\n",
       "elevationdifference                                 8\n",
       "censustract                                     58879\n",
       "floodzone                                      162683\n",
       "houseworship                                  2189014\n",
       "latitude                                        53114\n",
       "locationofcontents                             894425\n",
       "longitude                                       53114\n",
       "lowestadjacentgrade                           2070283\n",
       "lowestfloorelevation                          1946072\n",
       "numberoffloorsintheinsuredbuilding              16493\n",
       "nonprofitindicator                            2185575\n",
       "obstructiontype                                887315\n",
       "occupancytype                                     720\n",
       "originalconstructiondate                       366401\n",
       "originalnbdate                                      8\n",
       "amountpaidonbuildingclaim                       73133\n",
       "amountpaidoncontentsclaim                      715656\n",
       "amountpaidonincreasedcostofcomplianceclaim    1269995\n",
       "postfirmconstructionindicator                   71970\n",
       "ratemethod                                      65203\n",
       "smallbusinessindicatorbuilding                2168377\n",
       "state                                              12\n",
       "totalbuildinginsurancecoverage                      8\n",
       "totalcontentsinsurancecoverage                      8\n",
       "yearofloss                                          0\n",
       "reportedzip                                      1131\n",
       "primaryresidence                              1011533\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial review of variables:** <br>\n",
    "There are many missing values to deal with but all variables seem relevant. Only variable to drop initially is asofdate which just describes the date the dataset was downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop asofdate\n",
    "claims.drop(columns=['asofdate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical Variables** <br>\n",
    "All of the categorical variables have varying number of categories and methods of indication. Using the metadata downloaded with the dataset, clean up and reclassify the categories to make them easier to understand or look up. This includes turning arbitrary numerical indicators into string indicators. Then fill all NaNs with a new category \"not_given\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify categories for readability\n",
    "\n",
    "# First, fix invalid entries in nonprofitindicator, obstructiontype\n",
    "claims['nonprofitindicator'] = claims['nonprofitindicator'].replace('0', np.nan)\n",
    "claims['obstructiontype'] = claims['obstructiontype'].replace({'*':np.nan, 0:np.nan})\n",
    "\n",
    "# Define function to reclassify categories by column\n",
    "def reclass(df, col_list, r_dict_list):\n",
    "    for i in range(0,len(col_list)):\n",
    "        df[col_list[i]] = df[col_list[i]].replace(r_dict_list[i]) \n",
    "        \n",
    "# Define replacement dictionaries by column\n",
    "bdcst_d = {0.0:'N', 1.0:'F', 2.0:'U', 3.0:'C', 4.0:'S'}\n",
    "crsd_d = {0.0: 'SHFA0', 0.5:'SHFA5', 1.0:'SHFA10', 1.5:'SHFA15', 2.0:'SHFA20', 2.5:'SHFA25', 3.0:'SHFA30', 3.5:'SHFA35', 4.0:'SHFA40', 4.5:'SHFA45'}\n",
    "eci_d = {1.0:'nocert_pre82', 2.0:'nocert_post82', 3.0:'cert_bfe', 4.0:'cert_nobfe'}\n",
    "loc_d = {'Lowest floor only above ground level (No basement/enclosure/crawlspace/subgrade crawlspace)':'lowest_only', 'Lowest floor above ground level and higher floors (No basement/enclosure/crawlspace/subgrade crawlspace)':'lowest_above', 'Basement/Enclosure/Crawlspace/Subgrade Crawlspace and above':'bec_above', 'Manufactured (mobile) home or travel trailer on foundation':'mobile', 'Above ground level more than one full floor':'above', 'Basement/Enclosure/Crawlspace/Subgrade Crawlspace only':'bec_only'}\n",
    "ot_d = {1:'SF', 2:'MF_4', 3: 'MF_5+', 4:'NR'}\n",
    "rm_d = {1: 'M', 2: 'Sp', 3:'Al', 4:'V', 5:'U', 6:'Pr', 7:'R', 8:'Te', 9:'Mp'}\n",
    "obt_d = {1.0:'A', 10.0: 'B', 15.0:'C', 20.0: 'D', 24.0:'E', 30.0:'F', 34.0:'G', 40.0:'H', 50.0:'I', 54.0:'J', 60.0:'K', 70.0:'L', 80.0:'M', 90.0:'N', 92.0:'O', 94.0:'P', 95.0:'Q', 96.0:'R', 97.0:'S', 98.0:'T'}\n",
    "\n",
    "\n",
    "# Define list of necessary columns and associated dicts\n",
    "reclass_col = ['basementenclosurecrawlspacetype','crsdiscount', 'elevationcertificateindicator', 'locationofcontents', 'occupancytype', 'ratemethod', 'obstructiontype']\n",
    "\n",
    "reclass_dict = [bdcst_d, crsd_d, eci_d, loc_d, ot_d, rm_d, obt_d]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call reclass function\n",
    "reclass(claims, reclass_col, reclass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns: fill NaNs with 'not_given'\n",
    "\n",
    "# Define columns to fill NaNs\n",
    "cat_cols = ['agriculturestructureindicator', 'elevatedbuildingindicator', 'houseworship', 'nonprofitindicator', 'postfirmconstructionindicator', 'smallbusinessindicatorbuilding', 'primaryresidence', 'basementenclosurecrawlspacetype','condominiumindicator', 'crsdiscount', 'floodzone', 'elevationcertificateindicator', 'locationofcontents', 'occupancytype','obstructiontype', 'ratemethod']\n",
    "\n",
    "# Fill NaNs\n",
    "claims[cat_cols] = claims[cat_cols].fillna('not_given')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical Continuous Variables** <br>\n",
    "Numerical variables have many NaNs to fill. First, create a new '_NaN' column to keep track of where values were filled. Then fill with the mode of each column. Note that some of these have unexpected values at huge ranges that don't make sense for the dataset. May be an indication of additional missing values, but will leave them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical continuous columns: create NaN indicator column, then fill with mode\n",
    "\n",
    "# Define fill function\n",
    "def create_nancol_num(df, col_list):\n",
    "    for col in col_list:\n",
    "        df[col+'_NaN'] = np.where(np.isnan(df[col].values), 1, 0)\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Create list of applicable columns\n",
    "num_vars = ['lowestadjacentgrade', 'lowestfloorelevation','amountpaidonbuildingclaim', 'amountpaidoncontentsclaim', 'amountpaidonincreasedcostofcomplianceclaim', 'totalbuildinginsurancecoverage', 'totalcontentsinsurancecoverage', 'elevationdifference', 'basefloodelevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call fill function\n",
    "create_nancol_num(claims, num_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical Discrete Variables** <br>\n",
    "Handle the same as continuous variables. Create a '_NaN' column and then fill with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical discrete columns: create NaN indicator column, then fill with mode\n",
    "# Use create_nancol_num function as defined above\n",
    "\n",
    "#Create list of applicable columns\n",
    "disc_vars = ['numberoffloorsintheinsuredbuilding', 'policycount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call fill function\n",
    "create_nancol_num(claims, disc_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date Variables** <br>\n",
    "Convert the date variables into datetime objects in order to extract features. Yearofloss already exists, but month of loss may be relevant. Additionally year of construction and year of nb (or policy). Then create '_NaN' column to keep track of missing values and fill with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dateofloss, originalconstructiondate originalnbdate to datetime object\n",
    "\n",
    "# first fix invalid entry in constructiondate\n",
    "claims['originalconstructiondate'] = claims['originalconstructiondate'].replace('1111-11-11', np.nan)\n",
    "\n",
    "# convert to datetime\n",
    "claims['originalnbdate'] = pd.to_datetime(claims['originalnbdate'])\n",
    "claims['originalconstructiondate'] = pd.to_datetime(claims['originalconstructiondate'])\n",
    "claims['dateofloss'] = pd.to_datetime(claims['dateofloss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column for monthofloss and constructionyear, nbyear\n",
    "claims['monthofloss'] = claims['dateofloss'].dt.month\n",
    "claims['constructionyear'] = claims['originalconstructiondate'].dt.year\n",
    "claims['nbyear'] = claims['originalnbdate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New date columns: create NaN indicator column, then fill with mode\n",
    "# Use create_nancol_num function as defined above\n",
    "\n",
    "# Create list of applicable columns\n",
    "date_vars = ['monthofloss', 'constructionyear', 'nbyear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call fill function\n",
    "create_nancol_num(claims, date_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Location Variables** <br>\n",
    "Location essentially all describe the same thing, will likely be highly correlated with eachother. Note that the reportedzip variable has the least missing values and may be best suited for modeling if we need to drop correlated variables. For now, fill with 'not_given' except for lat/long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location variables: fill NaNs with 'not_given'\n",
    "\n",
    "# Define columns to fill NaNs\n",
    "loc_vars = ['reportedcity', 'countycode', 'censustract', 'state', 'reportedzip']\n",
    "\n",
    "# Fill NaNs\n",
    "claims[loc_vars] = claims[loc_vars].fillna('not_given')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agriculturestructureindicator                          0\n",
       "basefloodelevation                                     0\n",
       "basementenclosurecrawlspacetype                        0\n",
       "reportedcity                                           0\n",
       "condominiumindicator                                   0\n",
       "policycount                                            0\n",
       "countycode                                             0\n",
       "crsdiscount                                            0\n",
       "dateofloss                                             0\n",
       "elevatedbuildingindicator                              0\n",
       "elevationcertificateindicator                          0\n",
       "elevationdifference                                    0\n",
       "censustract                                            0\n",
       "floodzone                                              0\n",
       "houseworship                                           0\n",
       "latitude                                           53114\n",
       "locationofcontents                                     0\n",
       "longitude                                          53114\n",
       "lowestadjacentgrade                                    0\n",
       "lowestfloorelevation                                   0\n",
       "numberoffloorsintheinsuredbuilding                     0\n",
       "nonprofitindicator                                     0\n",
       "obstructiontype                                        0\n",
       "occupancytype                                          0\n",
       "originalconstructiondate                          366402\n",
       "originalnbdate                                         8\n",
       "amountpaidonbuildingclaim                              0\n",
       "amountpaidoncontentsclaim                              0\n",
       "amountpaidonincreasedcostofcomplianceclaim             0\n",
       "postfirmconstructionindicator                          0\n",
       "ratemethod                                             0\n",
       "smallbusinessindicatorbuilding                         0\n",
       "state                                                  0\n",
       "totalbuildinginsurancecoverage                         0\n",
       "totalcontentsinsurancecoverage                         0\n",
       "yearofloss                                             0\n",
       "reportedzip                                            0\n",
       "primaryresidence                                       0\n",
       "lowestadjacentgrade_NaN                                0\n",
       "lowestfloorelevation_NaN                               0\n",
       "amountpaidonbuildingclaim_NaN                          0\n",
       "amountpaidoncontentsclaim_NaN                          0\n",
       "amountpaidonincreasedcostofcomplianceclaim_NaN         0\n",
       "totalbuildinginsurancecoverage_NaN                     0\n",
       "totalcontentsinsurancecoverage_NaN                     0\n",
       "elevationdifference_NaN                                0\n",
       "basefloodelevation_NaN                                 0\n",
       "numberoffloorsintheinsuredbuilding_NaN                 0\n",
       "policycount_NaN                                        0\n",
       "monthofloss                                            0\n",
       "constructionyear                                       0\n",
       "nbyear                                                 0\n",
       "monthofloss_NaN                                        0\n",
       "constructionyear_NaN                                   0\n",
       "nbyear_NaN                                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing <br>\n",
    "Some categorical features have many classes, clean up to be easier to interpret. Note that additional features were developed based on date columns during the cleaning process above (e.g. year of construction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Floodzone** <br>\n",
    "Simplify floodzone categorical variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simplified floodzone variable\n",
    "\n",
    "conditions = [\n",
    "    (claims['floodzone'] == 'AE'),\n",
    "    (claims['floodzone'] == 'X'),\n",
    "    (claims['floodzone'] == 'VE'),\n",
    "    (claims['floodzone'] == 'not_given'),\n",
    "    (claims['floodzone'].str[0] == 'A'),\n",
    "    (claims['floodzone'].str[0] == 'V'),\n",
    "    (claims['floodzone'].str[0] == 'C')\n",
    "]\n",
    "\n",
    "options = ['AE', 'X', 'VE', 'not_given', 'A', 'V', 'C']\n",
    "\n",
    "claims['floodzone_simp'] = np.select(conditions, options, default='other') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obstruction Type** <br>\n",
    "Simplify obstructiontype variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simplified obstructiontype variable\n",
    "claims['obstype_simp'] = claims['obstructiontype']\n",
    "\n",
    "claims['obstype_simp'].replace('C', 'WO_cs', inplace=True)\n",
    "claims['obstype_simp'].replace(['D', 'E', 'F', 'G'], 'WO_bw', inplace=True)\n",
    "claims['obstype_simp'].replace(['B', 'H'], 'WO_nw', inplace=True)\n",
    "claims['obstype_simp'].replace(['I', 'J'], 'WO_nbw', inplace=True)\n",
    "claims['obstype_simp'].replace('K', 'WO', inplace=True)\n",
    "claims['obstype_simp'].replace('L', 'WC', inplace=True)\n",
    "claims['obstype_simp'].replace('M', 'WOC', inplace=True)\n",
    "claims['obstype_simp'].replace(['N', 'O'], 'WE', inplace=True)\n",
    "claims['obstype_simp'].replace(['P', 'Q', 'R', 'S', 'T'], 'WO_el', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create final dataframe** <br>\n",
    "Select relevant features, exclude lat/long, datetime vars, repetitive location variables. Use this new dataframe to get dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2418007 entries, 0 to 2418006\n",
      "Data columns (total 57 columns):\n",
      " #   Column                                          Dtype         \n",
      "---  ------                                          -----         \n",
      " 0   agriculturestructureindicator                   object        \n",
      " 1   basefloodelevation                              float64       \n",
      " 2   basementenclosurecrawlspacetype                 object        \n",
      " 3   reportedcity                                    object        \n",
      " 4   condominiumindicator                            object        \n",
      " 5   policycount                                     float64       \n",
      " 6   countycode                                      object        \n",
      " 7   crsdiscount                                     object        \n",
      " 8   dateofloss                                      datetime64[ns]\n",
      " 9   elevatedbuildingindicator                       object        \n",
      " 10  elevationcertificateindicator                   object        \n",
      " 11  elevationdifference                             float64       \n",
      " 12  censustract                                     object        \n",
      " 13  floodzone                                       object        \n",
      " 14  houseworship                                    object        \n",
      " 15  latitude                                        float64       \n",
      " 16  locationofcontents                              object        \n",
      " 17  longitude                                       float64       \n",
      " 18  lowestadjacentgrade                             float64       \n",
      " 19  lowestfloorelevation                            float64       \n",
      " 20  numberoffloorsintheinsuredbuilding              float64       \n",
      " 21  nonprofitindicator                              object        \n",
      " 22  obstructiontype                                 object        \n",
      " 23  occupancytype                                   object        \n",
      " 24  originalconstructiondate                        datetime64[ns]\n",
      " 25  originalnbdate                                  datetime64[ns]\n",
      " 26  amountpaidonbuildingclaim                       float64       \n",
      " 27  amountpaidoncontentsclaim                       float64       \n",
      " 28  amountpaidonincreasedcostofcomplianceclaim      float64       \n",
      " 29  postfirmconstructionindicator                   object        \n",
      " 30  ratemethod                                      object        \n",
      " 31  smallbusinessindicatorbuilding                  object        \n",
      " 32  state                                           object        \n",
      " 33  totalbuildinginsurancecoverage                  float64       \n",
      " 34  totalcontentsinsurancecoverage                  float64       \n",
      " 35  yearofloss                                      int64         \n",
      " 36  reportedzip                                     object        \n",
      " 37  primaryresidence                                object        \n",
      " 38  lowestadjacentgrade_NaN                         int64         \n",
      " 39  lowestfloorelevation_NaN                        int64         \n",
      " 40  amountpaidonbuildingclaim_NaN                   int64         \n",
      " 41  amountpaidoncontentsclaim_NaN                   int64         \n",
      " 42  amountpaidonincreasedcostofcomplianceclaim_NaN  int64         \n",
      " 43  totalbuildinginsurancecoverage_NaN              int64         \n",
      " 44  totalcontentsinsurancecoverage_NaN              int64         \n",
      " 45  elevationdifference_NaN                         int64         \n",
      " 46  basefloodelevation_NaN                          int64         \n",
      " 47  numberoffloorsintheinsuredbuilding_NaN          int64         \n",
      " 48  policycount_NaN                                 int64         \n",
      " 49  monthofloss                                     int64         \n",
      " 50  constructionyear                                float64       \n",
      " 51  nbyear                                          float64       \n",
      " 52  monthofloss_NaN                                 int64         \n",
      " 53  constructionyear_NaN                            int64         \n",
      " 54  nbyear_NaN                                      int64         \n",
      " 55  floodzone_simp                                  object        \n",
      " 56  obstype_simp                                    object        \n",
      "dtypes: datetime64[ns](3), float64(15), int64(16), object(23)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "# check data types\n",
    "claims.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to drop, drop them\n",
    "\n",
    "cols_to_drop = ['dateofloss', 'originalconstructiondate', 'originalnbdate', 'longitude', 'latitude', 'reportedcity', 'countycode', 'censustract', 'floodzone', 'obstructiontype', 'reportedzip']\n",
    "df = claims.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2418007, 46)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies for categorical columns\n",
    "d_cat = pd.get_dummies(df[['agriculturestructureindicator', 'elevatedbuildingindicator', 'houseworship', 'nonprofitindicator', 'postfirmconstructionindicator','smallbusinessindicatorbuilding', 'primaryresidence','basementenclosurecrawlspacetype', 'condominiumindicator', 'locationofcontents', 'crsdiscount', 'elevationcertificateindicator', 'occupancytype', 'ratemethod', 'obstype_simp', 'floodzone_simp', 'state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2418007, 174)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dummy columns and drop original cat columns\n",
    "\n",
    "df = df.drop(columns=['agriculturestructureindicator', 'elevatedbuildingindicator', 'houseworship', 'nonprofitindicator', 'postfirmconstructionindicator','smallbusinessindicatorbuilding', 'primaryresidence','basementenclosurecrawlspacetype', 'condominiumindicator', 'locationofcontents', 'crsdiscount', 'elevationcertificateindicator', 'occupancytype', 'ratemethod', 'obstype_simp', 'floodzone_simp', 'state'])\n",
    "df = pd.concat([df, d_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2418007, 203)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2418007 entries, 0 to 2418006\n",
      "Columns: 203 entries, basefloodelevation to state_not_given\n",
      "dtypes: float64(13), int64(16), uint8(174)\n",
      "memory usage: 936.2 MB\n"
     ]
    }
   ],
   "source": [
    "# check datatypes again\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate predictor and response variables into X and y\n",
    "\n",
    "X = df.drop(columns=['amountpaidonbuildingclaim', 'amountpaidonbuildingclaim_NaN'])\n",
    "y = df[['amountpaidonbuildingclaim']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling** <br>\n",
    "Use StandardScaler to scale features for modeling. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate scaler based on train set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# scale train and test sets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export preprocessed datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e84f34b6b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_train_scaled.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_test_scaled.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_scaled.to_csv('X_train_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv('X_test_scaled.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
